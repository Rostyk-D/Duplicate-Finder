# ğŸ—‚ Duplicate Finder â€” Images & Videos

**Duplicate Finder** is an application on **Streamlit** that automatically finds duplicate images and videos using **perceptual hashes (pHash)**.
The program supports multiprocessing, caching of results, and a convenient interface for viewing and removing duplicates.
<img width="1915" height="963" alt="image" src="https://github.com/user-attachments/assets/e5f6357a-ba1c-4cbf-a691-470c5474e196" />

---

## ğŸš€ Main feauters

âœ… Search for duplicate **images** based on content similarity (not just names).  
âœ… Search for duplicate **videos** based on frame similarity.  
âœ… Multi-processor support for fast processing.  
âœ… **Caching** of file hashes to save time during repeated checks.  
âœ… Determination of **similarity degree** via a configurable threshold (Hamming distance).  
âœ… Ability to delete duplicates in **Recycle Bin** (via `send2trash`).  
âœ… Convenient Streamlit interface with **image/video preview**.  
âœ… Support for selecting a local folder, uploading individual files or ZIP archives.

---

## ğŸ§  How this work

### ğŸ”¹ Image
1. Each image is divided into **4 quadrants**.
2. For each quadrant, a **pHash** (perceptual hash) is calculated.
3. All hashes are compared, and if the average **Hamming distance** between them is lower than a given threshold, the files are considered similar.

### ğŸ”¹ Video
1. Frames are extracted from the video every *N seconds* (`Config.FRAME_INTERVAL_SEC`).
2. **pHash** is calculated for each frame.
3. If two videos have enough similar frames (by the number of `Config.MIN_MATCHES`), they are considered duplicates.
---

## âš™ï¸ Technologies used

- ğŸ **Python 3.12+**
- ğŸ–¼ **Pillow** â€” working with images
- ğŸ§® **imagehash** â€” calculating perceptual hashes
- ğŸ¥ **OpenCV (cv2)** â€” working with video
- ğŸ’¾ **pickle** â€” caching hashes
- ğŸ”„ **concurrent.futures / multiprocessing** â€” parallel processing
- ğŸ§± **Streamlit** â€” building interactive UI
- ğŸ—‘ **send2trash** â€” safe file deletion to the trash
- ğŸ§° **Tki

---

## ğŸ§° Startup Instructions

### 1ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

or manually:
```bash
pip install streamlit pillow imagehash opencv-python send2trash
```

---

### 2ï¸âƒ£ Run the application
```bash
streamlit run app.py
```

---

### 3ï¸âƒ£ Usage
1. Select the mode:
  - **Images** â€“ to search for duplicate images
  - **Videos** â€“ to search for duplicate videos
2. Specify the source:
  - ğŸ“ **Local folder** â€” select a folder with files
  - ğŸ“¤ **Upload files** â€” upload individual files
  - ğŸ“¦ **Upload ZIP** â€” upload an archive with files
3. Click **ğŸ” Scan / Update** to create or update the hash cache.
4. View the found duplicates, delete unnecessary files (via the trash).
---

## âš™ï¸ Configuration

| Parameter | Description | Default value |
|-----------|------|--------------------------|
| `FRAME_INTERVAL_SEC` | Interval between frames when analyzing video | 2 sec |
| `HAMMING_THRESHOLD` | Frame similarity threshold | 15 |
| `MIN_MATCHES` | Minimum number of similar frames between videos | 7 |
| `SAVE_INTERVAL_DEFAULT` | How often to save the cache during processing | 50 |
| `WORKERS_DEFAULT` | Number of processes | 8 (or less than the number of CPUs) |

---

## ğŸ“ Project structure

```
duplicate_finder/
â”‚
â”œâ”€â”€ app.py               # Main program file
â”œâ”€â”€ streamlit_uploads/   # Temporary upload files
â”œâ”€â”€ requirements.txt     # Dependency list
â””â”€â”€ README.md            # Project description
```

---

## ğŸ§© Main Classes

| Class | Purpose |
|------|---------------|
| `Config` | Stores global application settings |
| `CacheManager` | Loads and stores hash cache |
| `ImageSplitter` | Splits images into quadrants |
| `ImageHasher` | Computes hashes for images |
| `VideoHasher` | Computes hashes for videos |
| `DuplicateFinder` | Compares hashes and finds duplicates |
| `UI` | Responsible

---

## ğŸ§¹ Secure deletion
Files are not permanently deleted - they are **moved to the trash** via the `send2trash` library.
